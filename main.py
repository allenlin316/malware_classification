import torch
from torch import nn
from torchvision import transforms,datasets
import numpy 
from tqdm import tqdm

file_name='classifier.pth' 
device=torch.device('cuda') # 'cuda'/'cpu'
patience = 100
num_classes=3
train_size=38
valid_size=1
batch_size=4
learning_rate=0.001
step_size=1000 # Reriod of learning rate decay
epochs=1000
transforms=transforms.Compose([
    transforms.Resize((224,224)),
    transforms.RandomRotation(degrees=15),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    #transforms.RandomGrayscale(p=0.1),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
])
dataset=datasets.ImageFolder('malware_images',transform=transforms) 
train_data,valid_data=torch.utils.data.random_split(dataset,[train_size,valid_size]) 
train_loader=torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True) 
valid_loader=torch.utils.data.DataLoader(valid_data,batch_size=batch_size,shuffle=False) 


class my_Model(nn.Module):
    def __init__(self, num_classes):
        super(my_Model, self).__init__()
        self.my_Model = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1), 
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2), 

            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2), 
        )
        self.fc = nn.Sequential(
            nn.Linear(32 * 56 * 56, 128),
            nn.ReLU(inplace=True),
            #nn.Dropout(0.5),
#             nn.Linear(1024, 512),
#             nn.ReLU(inplace=True),
            #nn.Dropout(0.5),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.my_Model(x)
        x = x.view(x.size(0), -1) # Flatten the tensor
        x = self.fc(x) # Fully connected layers
        return x


classifier=my_Model(num_classes=num_classes).to(device)
print(classifier)
criterion=nn.CrossEntropyLoss() # 分類
#optimizer=torch.optim.Adadelta(classifier.parameters(),lr=learning_rate) # import torch
optimizer=torch.optim.SGD(classifier.parameters(),lr=learning_rate) # import torch
scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size,0.1) # import torch
train_acc_his,train_losses_his,valid_acc_his,valid_losses_his=[],[],[],[]
best_loss, stale = 1.5, 0
for i in range(1,epochs+1):
    print('Running Epoch:'+str(i))
    train_correct,train_loss,train_total,valid_correct,valid_loss,valid_total=0,0,0,0,0,0
    classifier.train()
    for img,cls in tqdm(train_loader, desc=f"Epoch {i} - Training"): # 一個batch的img、cls。img：[batch_size,3,224,224]，cls：[batch_size]
        img,cls=img.to(device),cls.to(device)
        pred=classifier(img) # pred：[batch_size,num_classes]
        loss=criterion(pred,cls) # loss.item()：一個batch的平均loss，[1]
        output_id=torch.max(pred,dim=1)[1] # output_id：網路輸出編號(0表示預測為第一個輸出)，[batch_size]
        train_correct+=numpy.sum(torch.eq(cls,output_id).cpu().numpy()) # 累加計算每一epoch正確預測總數，import numpy
        train_loss+=loss.item()*img.size(0) # 累加計算每一epoch的loss總和。loss.item()：一個batch的平均loss，[1]。img.size(0)：一個batch的訓練資料總數
        train_total+=img.size(0) # 累加計算訓練資料總數
        optimizer.zero_grad() # 權重梯度歸零
        loss.backward() # 計算每個權重的loss梯度
        optimizer.step() # 權重更新
    scheduler.step()

    classifier.eval()
    for img,cls in valid_loader: # 一個batch的img、cls。img：[batch_size,3,224,224]，cls：[batch_size]
        img,cls=img.to(device),cls.to(device)
        pred=classifier(img) # pred：[batch_size,num_classes]
        loss=criterion(pred,cls) # loss.item()：一個batch的平均loss，[1]
        output_id=torch.max(pred,dim=1)[1] # output_id：網路輸出編號(0表示預測為第一個輸出)，[batch_size]
        valid_correct+=numpy.sum(torch.eq(cls,output_id).cpu().numpy()) # 累加計算每一epoch正確預測總數
        valid_loss+=loss.item()*img.size(0) # 累加計算每一epoch的loss總和。loss.item()：一個batch的平均loss，[1]。img.size(0)：一個batch的驗證資料總數
        valid_total+=img.size(0) # 累加計算驗證資料總數

    train_acc=train_correct/train_total*100 # 計算每一個epoch的平均訓練正確率(%)
    train_loss=train_loss/train_total # 計算每一個epoch的平均訓練loss
    valid_acc=valid_correct/valid_total*100 # 計算每一個epoch的平均驗證正確率(%)
    valid_loss=valid_loss/valid_total # 計算每一個epoch的平均驗證loss
    train_acc_his.append(train_acc) # 累積紀錄每一個epoch的平均訓練正確率(%)，[epochs]
    train_losses_his.append(train_loss) # 累積記錄每一個epoch的平均訓練loss，[epochs]
    valid_acc_his.append(valid_acc) # 累積紀錄每一個epoch的平均驗證正確率(%)，[epochs]
    valid_losses_his.append(valid_loss) # 累積記錄每一個epoch的平均驗證loss，[epochs]
    print('Training Loss='+str(train_loss))
    print('Training Accuracy(%)='+str(train_acc))
    print('Validation Accuracy(%)='+str(valid_acc))
    if train_loss < best_loss:
        print(f"Best model found at epoch {i+1}, saving model")
        torch.save(classifier.state_dict(), file_name)
        best_loss = train_loss
        stale = 0
    else:
        stale += 1
        if stale > patience:
            print(f"No improvment {patience} consecutive epochs, early stopping")
            break

import matplotlib.pyplot as plt
plt.figure(figsize=(15,10))
plt.subplot(211)
plt.plot(train_acc_his,'b',label='training accuracy')
plt.plot(valid_acc_his,'r',label='validation accuracy')
plt.title('Accuracy(%)')
plt.legend(loc='best')
plt.subplot(212)
plt.plot(train_losses_his,'b',label='training loss')
plt.plot(valid_losses_his,'r',label='validation loss')
plt.title('Loss')
plt.legend(loc='best')
#plt.show()
plt.savefig("training and validation fig.jpg")

# +
# torch.save(classifier.state_dict(),file_name)

# +
# Prediction
from torchvision import transforms
from torchvision.io import read_image
import os
from PIL import Image
import cv2
file_name = "classifier.pth"
classifier = my_Model(num_classes=3).to(device)
classifier.load_state_dict(torch.load(file_name))

# 取得影像
TestImage='Testing_images/'
transforms=transforms.Compose([
    transforms.ToPILImage(), # to PIL format
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
])
all_image_name=os.listdir(TestImage) # 所有影像檔名(含.jpg)，import os

classifier.eval()
for image_name in all_image_name:
    #img=Image.open(TestImage+image_name,mode='r')
    img = read_image(TestImage+image_name)
    img = img[:3, :, :]
    #img = cv2.imread(TestImage+image_name)
    #print(img.shape)
    img=transforms(img) # [1,28,28]
    img=img.unsqueeze(0) # [1,1,224,224]
    img=img.to(device)
    pred=classifier(img)
    output_id=torch.max(pred,dim=1)[1] # output_id：網路輸出編號(0表示預測為第一個輸出)，[batch_size]
    print(image_name, output_id.item()) #0 represents label 3, 1 represents label 6, 2 represents label 8, 3 represents label 9
# -


